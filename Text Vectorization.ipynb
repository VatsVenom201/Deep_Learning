{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae86579a-23ff-473c-b70c-e072624d96ce",
   "metadata": {},
   "source": [
    "# 1️⃣ Bag of Words (BoW)\n",
    "### What problem it solves\n",
    "\n",
    "##### Convert text into numbers so ML models can process it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2291b-82fa-40c1-ae49-7e07b00f3cc8",
   "metadata": {},
   "source": [
    "### Working (step-by-step)\n",
    "#### Step 1: Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e09d1-ef4d-4e8c-91d0-23d817fca0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1: \"I love deep learning\"\n",
    "D2: \"I love machine learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053be76c-77a2-406a-842d-6cbd6c59c017",
   "metadata": {},
   "source": [
    "#### Step 2: Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217d817-8d7e-4df7-8aeb-f2bedce9a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary = [I, love, deep, machine, learning]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b7685-ad36-4af0-a0a6-bb531a728aff",
   "metadata": {},
   "source": [
    "#### Step 3: Count word frequency per document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29931a8-ce60-4348-8c1d-57520f0de250",
   "metadata": {},
   "source": [
    "| Document | I | love | deep | machine | learning |\n",
    "| -------- | - | ---- | ---- | ------- | -------- |\n",
    "| D1       | 1 | 1    | 1    | 0       | 1        |\n",
    "| D2       | 1 | 1    | 0    | 1       | 1        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20667058-08be-4835-88be-7bc0927b42c0",
   "metadata": {},
   "source": [
    "#### Step 4: Vector output\n",
    "\n",
    "##### Each document → fixed-length vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2bbae-97b6-469e-a0a2-0f648f267405",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 → [1, 1, 1, 0, 1]\n",
    "D2 → [1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c74e8f-7e80-41ed-bec2-80e2b402b7c6",
   "metadata": {},
   "source": [
    "#### Key properties\n",
    "\n",
    "Ignores word order\n",
    "\n",
    "Ignores meaning\n",
    "\n",
    "High dimensional & sparse\n",
    "\n",
    "#### How ML uses it\n",
    "\n",
    "Each column = feature\n",
    "\n",
    "Model learns weights per word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467a991-3368-4f82-ab26-388d70ef9c66",
   "metadata": {},
   "source": [
    "# 2️⃣ TF-IDF\n",
    "### What problem it improves\n",
    "\n",
    "#### BoW treats all words equally → TF-IDF adds importance weighting\n",
    "\n",
    "## Working\n",
    "#### Step 1: Term Frequency (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9112a-a6a9-4ea4-ad17-8094f574a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF(word, doc) = count(word in doc) / total words in doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28dd56-b338-4e99-b2e0-392d971b8446",
   "metadata": {},
   "source": [
    "#### Step 2: Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20302450-29ea-4bff-a3c0-c88f6acebb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF(word) = log(N / df(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551a6eb-7ded-44bd-b243-1ca5df350979",
   "metadata": {},
   "source": [
    "N = total documents\n",
    "\n",
    "df = documents containing the word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017f330-87e3-4f3a-b0e9-ed23aa46c002",
   "metadata": {},
   "source": [
    "#### Step 3: TF-IDF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f4816-6206-48e6-9c5b-88b101ed51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF-IDF = TF × IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be699a-e164-4840-b6ee-d744c75e1cc1",
   "metadata": {},
   "source": [
    "#### Example result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f286c-c496-46da-8efc-270b185c1c37",
   "metadata": {},
   "source": [
    "| Document | I    | love | deep | machine | learning |\n",
    "| -------- | ---- | ---- | ---- | ------- | -------- |\n",
    "| D1       | 0.21 | 0.21 | 0.55 | 0.00    | 0.31     |\n",
    "| D2       | 0.21 | 0.21 | 0.00 | 0.55    | 0.31     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2caea25-0e43-475d-b9be-15f27eb3fb64",
   "metadata": {},
   "source": [
    "### What the score means\n",
    "\n",
    "Higher score → more important in that document\n",
    "\n",
    "Still no semantics\n",
    "\n",
    "### How ML uses it\n",
    "\n",
    "Same as BoW:\n",
    "\n",
    "Vector + label → classifier/regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e6e1f8-8a5f-4997-8126-19ba268c9375",
   "metadata": {},
   "source": [
    "# 3️⃣ Word2Vec (Embedding Learning)\n",
    "### What problem it solves\n",
    "\n",
    "#### BoW / TF-IDF:\n",
    "\n",
    "Sparse\n",
    "\n",
    "No meaning\n",
    "\n",
    "No similarity\n",
    "\n",
    "#### Word2Vec learns semantic meaning.\n",
    "\n",
    "Core idea\n",
    "\n",
    "Words appearing in similar contexts have similar meanings.\n",
    "\n",
    "## Architecture (Skip-Gram example)\n",
    "#### Input\n",
    "\n",
    "Center word (one-hot vector)\n",
    "\n",
    "#### Output\n",
    "\n",
    "Context word (one-hot vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cdd459-892e-42cd-9005-112a51f15c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input → Hidden → Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae63f30-5c34-4f9f-bc78-b732365b78de",
   "metadata": {},
   "source": [
    "#### Hidden layer = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f2f5ac-9a7e-4ce7-8035-879c3e124a49",
   "metadata": {},
   "source": [
    "### Training process\n",
    "\n",
    "Sentence:\n",
    "\n",
    "\"I love deep learning\"\n",
    "\n",
    "\n",
    "Window size = 1\n",
    "\n",
    "Training pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8add1d-fc60-4a9d-a93b-b84b7d19ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "(love → I), (love → deep)\n",
    "(deep → love), (deep → learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7989d547-89cf-42df-bf6e-e4077b356fde",
   "metadata": {},
   "source": [
    "#### Neural Network structure\n",
    "\n",
    "Input layer → one-hot (V size)\n",
    "\n",
    "Hidden layer → D neurons (embedding dimension)\n",
    "\n",
    "Output layer → V size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e99801-f0b5-4368-8010-5f0908b9134e",
   "metadata": {},
   "source": [
    "#### Learning via backprop\n",
    "\n",
    "Pull related words closer\n",
    "\n",
    "Push unrelated words apart\n",
    "\n",
    "#### After training:\n",
    "\n",
    "Keep embedding matrix\n",
    "\n",
    "Discard NN\n",
    "\n",
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a212d9-de93-4064-9e10-9a9079ac70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding(\"deep\") = [0.12, -0.87, 0.44, ...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2c6e0-58ec-4c21-ab53-a7c514e0777e",
   "metadata": {},
   "source": [
    "### Properties\n",
    "\n",
    "Dense\n",
    "\n",
    "Semantic similarity\n",
    "\n",
    "Static (same vector everywhere)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989e937-7798-4724-bfbd-68d04478d144",
   "metadata": {},
   "source": [
    "# 4️⃣ Self-Attention (Contextual Embeddings)\n",
    "### What problem it solves\n",
    "\n",
    "#### Word2Vec cannot change meaning per sentence.\n",
    "\n",
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1248564-0394-4971-8bbb-8c547a4d316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X ∈ (T × n)  → embeddings of sentence words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1305c2e-53a2-4e3e-932c-6f00c4b0e939",
   "metadata": {},
   "source": [
    "### Working\n",
    "#### Step 1: Linear projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7958d541-b1fe-47f5-8d6a-41d42d757802",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = X · WQ\n",
    "K = X · WK\n",
    "V = X · WV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1a5b9-7b9a-4b11-8453-2364f8cee332",
   "metadata": {},
   "source": [
    "#### Step 2: Attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81736241-98cd-4439-a91e-abf5d63f6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores = (Q · Kᵀ) / √dₖ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6dc48-f842-4068-ab74-9dfee3f297e8",
   "metadata": {},
   "source": [
    "Meaning:\n",
    "\n",
    "How much each word relates to every other word\n",
    "\n",
    "#### Step 3: Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa8b6e-384d-4636-9dd0-9df1f3516102",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attention = softmax(Scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec0a67-fe43-425b-9c9a-1ca1b7f42ca2",
   "metadata": {},
   "source": [
    "Turns scores into probabilities.\n",
    "\n",
    "#### Step 4: Weighted sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993bf2fb-6940-4c6d-9daa-93852cb15f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = Attention · V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e18f2f-a208-47d0-81ff-8c8065fb79fb",
   "metadata": {},
   "source": [
    "Each word becomes a context-aware vector\n",
    "\n",
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524eca4c-7ebc-452b-bf91-30bb9f3e35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Same word → different vector in different sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe6544-acd5-4d99-a14b-5dfcbdf7c3f3",
   "metadata": {},
   "source": [
    "#### Properties\n",
    "\n",
    "Dense\n",
    "\n",
    "Semantic + contextual\n",
    "\n",
    "Computed dynamically\n",
    "\n",
    "Not stored per word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169b613-9913-4dba-bb5b-b8b2ff6b74e5",
   "metadata": {},
   "source": [
    "# 5️⃣ Full comparison (working perspective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca48432-ec35-49be-9637-3d44865ddc12",
   "metadata": {},
   "source": [
    "| Method         | How vectors are created             | Meaning captured | Context aware |\n",
    "| -------------- | ----------------------------------- | ---------------- | ------------- |\n",
    "| BoW            | Count words                         | ❌                | ❌             |\n",
    "| TF-IDF         | Count × importance                  | ❌                | ❌             |\n",
    "| Word2Vec       | Learn from context windows          | ✅                | ❌             |\n",
    "| Self-Attention | Compute relevance between all words | ✅                | ✅             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3f301-7f83-43fe-a194-d066ed00fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW        → \"Which words?\"\n",
    "TF-IDF     → \"Which words matter?\"\n",
    "Word2Vec   → \"What do words mean?\"\n",
    "Self-Attn  → \"What do words mean here?\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
